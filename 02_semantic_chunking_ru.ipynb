{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "## Введение в семантическое чанкование\n",
    "Чанкование текста - важный этап в Retrieval-Augmented Generation (RAG), где большие тексты делятся на осмысленные сегменты для повышения точности поиска.\n",
    "В отличие от чанкования фиксированной длины, семантическое чанкование разделяет текст на основе смысловой схожести между предложениями.\n",
    "\n",
    "### Методы определения границ чанков:\n",
    "- **Процентиль**: Находит X-й процентиль всех различий схожести и разделяет чанки там, где падение превышает это значение.\n",
    "- **Стандартное отклонение**: Разделяет там, где схожесть падает более чем на X стандартных отклонений ниже среднего.\n",
    "- **Межквартильный размах (IQR)**: Использует межквартильное расстояние (Q3 - Q1) для определения точек разделения.\n",
    "\n",
    "Этот ноутбук реализует семантическое чанкование **с использованием метода процентилей** и оценивает его производительность на примере текста."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройка окружения\n",
    "Начнём с импорта необходимых библиотек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Извлечение текста из PDF-файла\n",
    "Для реализации RAG нам сначала нужен источник текстовых данных. В данном случае мы извлекаем текст из PDF-файла с помощью библиотеки PyMuPDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Understanding Artificial Intelligence \n",
      "Chapter 1: Introduction to Artificial Intelligence \n",
      "Artificial intelligence (AI) refers to the ability of a digital computer or computer-controlled robot \n",
      "to perform tasks commonly associated with intelligent beings. The term is frequently applied to \n",
      "the project of developing systems endowed with the intellectual processes characteristic of \n",
      "humans, such as the ability to reason, discover meaning, generalize, or learn from past \n",
      "experience. Over the past f\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Извлекает текст из PDF-файла.\n",
    "\n",
    "    Аргументы:\n",
    "    pdf_path (str): Путь к PDF-файлу.\n",
    "\n",
    "    Возвращает:\n",
    "    str: Извлечённый текст из PDF.\n",
    "    \"\"\"\n",
    "    # Открываем PDF-файл\n",
    "    mypdf = fitz.open(pdf_path)\n",
    "    all_text = \"\"  # Инициализируем пустую строку для хранения извлечённого текста\n",
    "    \n",
    "    # Итерируемся по каждой странице в PDF\n",
    "    for page in mypdf:\n",
    "        # Извлекаем текст с текущей страницы и добавляем пробел\n",
    "        all_text += page.get_text(\"text\") + \" \"\n",
    "\n",
    "    # Возвращаем извлечённый текст, очищенный от начальных/конечных пробелов\n",
    "    return all_text.strip()\n",
    "\n",
    "# Определяем путь к PDF-файлу\n",
    "pdf_path = \"data/AI_Information.pdf\"\n",
    "\n",
    "# Извлекаем текст из PDF-файла\n",
    "extracted_text = extract_text_from_pdf(pdf_path)\n",
    "\n",
    "# Выводим первые 500 символов извлечённого текста\n",
    "print(extracted_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настройка клиента OpenAI API\n",
    "Инициализируем клиент OpenAI для генерации эмбеддингов и ответов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализируем клиент OpenAI с базовым URL и API ключом\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.studio.nebius.com/v1/\",\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")  # Получаем API ключ из переменных окружения\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание эмбеддингов на уровне предложений\n",
    "Разделяем текст на предложения и генерируем эмбеддинги."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 257 sentence embeddings.\n"
     ]
    }
   ],
   "source": [
    "def get_embedding(text, model=\"BAAI/bge-en-icl\"):\n",
    "    \"\"\"\n",
    "    Создаёт эмбеддинг для заданного текста с использованием OpenAI.\n",
    "\n",
    "    Аргументы:\n",
    "    text (str): Входной текст.\n",
    "    model (str): Название модели эмбеддингов.\n",
    "\n",
    "    Возвращает:\n",
    "    np.ndarray: Вектор эмбеддинга.\n",
    "    \"\"\"\n",
    "    response = client.embeddings.create(model=model, input=text)\n",
    "    return np.array(response.data[0].embedding)\n",
    "\n",
    "# Разделяем текст на предложения (базовое разделение)\n",
    "sentences = extracted_text.split(\". \")\n",
    "\n",
    "# Генерируем эмбеддинги для каждого предложения\n",
    "embeddings = [get_embedding(sentence) for sentence in sentences]\n",
    "\n",
    "print(f\"Generated {len(embeddings)} sentence embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вычисление различий схожести\n",
    "Вычисляем косинусную схожесть между последовательными предложениями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"\n",
    "    Вычисляет косинусную схожесть между двумя векторами.\n",
    "\n",
    "    Аргументы:\n",
    "    vec1 (np.ndarray): Первый вектор.\n",
    "    vec2 (np.ndarray): Второй вектор.\n",
    "\n",
    "    Возвращает:\n",
    "    float: Косинусная схожесть.\n",
    "    \"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "# Вычисляем схожесть между последовательными предложениями\n",
    "similarities = [cosine_similarity(embeddings[i], embeddings[i + 1]) for i in range(len(embeddings) - 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация семантического чанкования\n",
    "Реализуем три различных метода для нахождения точек разделения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_breakpoints(similarities, method=\"percentile\", threshold=90):\n",
    "    \"\"\"\n",
    "    Вычисляет точки разделения для чанков на основе падений схожести.\n",
    "\n",
    "    Аргументы:\n",
    "    similarities (List[float]): Список оценок схожести между предложениями.\n",
    "    method (str): 'percentile', 'standard_deviation' или 'interquartile'.\n",
    "    threshold (float): Пороговое значение (процентиль для 'percentile', стандартные отклонения для 'standard_deviation').\n",
    "\n",
    "    Возвращает:\n",
    "    List[int]: Индексы, где должны происходить разделения чанков.\n",
    "    \"\"\"\n",
    "    # Определяем пороговое значение на основе выбранного метода\n",
    "    if method == \"percentile\":\n",
    "        # Вычисляем X-й процентиль оценок схожести\n",
    "        threshold_value = np.percentile(similarities, threshold)\n",
    "    elif method == \"standard_deviation\":\n",
    "        # Вычисляем среднее и стандартное отклонение оценок схожести\n",
    "        mean = np.mean(similarities)\n",
    "        std_dev = np.std(similarities)\n",
    "        # Устанавливаем пороговое значение как среднее минус X стандартных отклонений\n",
    "        threshold_value = mean - (threshold * std_dev)\n",
    "    elif method == \"interquartile\":\n",
    "        # Вычисляем первый и третий квартили (Q1 и Q3)\n",
    "        q1, q3 = np.percentile(similarities, [25, 75])\n",
    "        # Устанавливаем пороговое значение по правилу IQR для выбросов\n",
    "        threshold_value = q1 - 1.5 * (q3 - q1)\n",
    "    else:\n",
    "        # Вызываем ошибку, если предоставлен недопустимый метод\n",
    "        raise ValueError(\"Invalid method. Choose 'percentile', 'standard_deviation', or 'interquartile'.\")\n",
    "\n",
    "    # Определяем индексы, где схожесть падает ниже порогового значения\n",
    "    return [i for i, sim in enumerate(similarities) if sim < threshold_value]\n",
    "\n",
    "# Вычисляем точки разделения с использованием метода процентилей с порогом 90\n",
    "breakpoints = compute_breakpoints(similarities, method=\"percentile\", threshold=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разделение текста на семантические чанки\n",
    "Разделяем текст на основе вычисленных точек разделения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of semantic chunks: 231\n",
      "\n",
      "First text chunk:\n",
      "Understanding Artificial Intelligence \n",
      "Chapter 1: Introduction to Artificial Intelligence \n",
      "Artificial intelligence (AI) refers to the ability of a digital computer or computer-controlled robot \n",
      "to perform tasks commonly associated with intelligent beings.\n"
     ]
    }
   ],
   "source": [
    "def split_into_chunks(sentences, breakpoints):\n",
    "    \"\"\"\n",
    "    Разделяет предложения на семантические чанки.\n",
    "\n",
    "    Аргументы:\n",
    "    sentences (List[str]): Список предложений.\n",
    "    breakpoints (List[int]): Индексы, где должно происходить разделение.\n",
    "\n",
    "    Возвращает:\n",
    "    List[str]: Список текстовых чанков.\n",
    "    \"\"\"\n",
    "    chunks = []  # Инициализируем пустой список для хранения чанков\n",
    "    start = 0  # Инициализируем начальный индекс\n",
    "\n",
    "    # Итерируемся по каждой точке разделения для создания чанков\n",
    "    for bp in breakpoints:\n",
    "        # Добавляем чанк предложений от start до текущей точки разделения\n",
    "        chunks.append(\". \".join(sentences[start:bp + 1]) + \".\")\n",
    "        start = bp + 1  # Обновляем начальный индекс на следующее предложение после точки разделения\n",
    "\n",
    "    # Добавляем оставшиеся предложения как последний чанк\n",
    "    chunks.append(\". \".join(sentences[start:]))\n",
    "    return chunks  # Возвращаем список чанков\n",
    "\n",
    "# Создаём чанки с помощью функции split_into_chunks\n",
    "text_chunks = split_into_chunks(sentences, breakpoints)\n",
    "\n",
    "# Выводим количество созданных чанков\n",
    "print(f\"Number of semantic chunks: {len(text_chunks)}\")\n",
    "\n",
    "# Выводим первый чанк для проверки результата\n",
    "print(\"\\nFirst text chunk:\")\n",
    "print(text_chunks[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание эмбеддингов для семантических чанков\n",
    "Создаём эмбеддинги для каждого чанка для последующего поиска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text_chunks):\n",
    "    \"\"\"\n",
    "    Создаёт эмбеддинги для каждого текстового чанка.\n",
    "\n",
    "    Аргументы:\n",
    "    text_chunks (List[str]): Список текстовых чанков.\n",
    "\n",
    "    Возвращает:\n",
    "    List[np.ndarray]: Список векторов эмбеддингов.\n",
    "    \"\"\"\n",
    "    # Генерируем эмбеддинги для каждого текстового чанка с помощью функции get_embedding\n",
    "    return [get_embedding(chunk) for chunk in text_chunks]\n",
    "\n",
    "# Создаём эмбеддинги чанков с помощью функции create_embeddings\n",
    "chunk_embeddings = create_embeddings(text_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выполнение семантического поиска\n",
    "Используем косинусную схожесть для поиска наиболее релевантных чанков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_search(query, text_chunks, chunk_embeddings, k=5):\n",
    "    \"\"\"\n",
    "    Находит наиболее релевантные текстовые чанки для запроса.\n",
    "\n",
    "    Аргументы:\n",
    "    query (str): Поисковый запрос.\n",
    "    text_chunks (List[str]): Список текстовых чанков.\n",
    "    chunk_embeddings (List[np.ndarray]): Список эмбеддингов чанков.\n",
    "    k (int): Количество возвращаемых результатов.\n",
    "\n",
    "    Возвращает:\n",
    "    List[str]: Топ-k релевантных чанков.\n",
    "    \"\"\"\n",
    "    # Генерируем эмбеддинг для запроса\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    # Вычисляем косинусную схожесть между эмбеддингом запроса и каждым эмбеддингом чанка\n",
    "    similarities = [cosine_similarity(query_embedding, emb) for emb in chunk_embeddings]\n",
    "    \n",
    "    # Получаем индексы топ-k наиболее схожих чанков\n",
    "    top_indices = np.argsort(similarities)[-k:][::-1]\n",
    "    \n",
    "    # Возвращаем топ-k наиболее релевантных текстовых чанков\n",
    "    return [text_chunks[i] for i in top_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is 'Explainable AI' and why is it considered important?\n",
      "Context 1:\n",
      "\n",
      "Explainable AI (XAI) \n",
      "Explainable AI (XAI) aims to make AI systems more transparent and understandable. Research in \n",
      "XAI focuses on developing methods for explaining AI decisions, enhancing trust, and improving \n",
      "accountability.\n",
      "========================================\n",
      "Context 2:\n",
      "\n",
      "Transparency and Explainability \n",
      "Transparency and explainability are essential for building trust in AI systems. Explainable AI (XAI) \n",
      "techniques aim to make AI decisions more understandable, enabling users to assess their \n",
      "fairness and accuracy.\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Загружаем валидационные данные из JSON-файла\n",
    "with open('data/val.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Извлекаем первый запрос из валидационных данных\n",
    "query = data[0]['question']\n",
    "\n",
    "# Получаем топ 2 релевантных чанка\n",
    "top_chunks = semantic_search(query, text_chunks, chunk_embeddings, k=2)\n",
    "\n",
    "# Выводим запрос\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# Выводим топ 2 наиболее релевантных текстовых чанка\n",
    "for i, chunk in enumerate(top_chunks):\n",
    "    print(f\"Context {i+1}:\\n{chunk}\\n{'='*40}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерация ответа на основе извлечённых чанков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем системный промт для AI-ассистента\n",
    "system_prompt = \"You are an AI assistant that strictly answers based on the given context. If the answer cannot be derived directly from the provided context, respond with: 'I do not have enough information to answer that.'\"\n",
    "\n",
    "def generate_response(system_prompt, user_message, model=\"meta-llama/Llama-3.2-3B-Instruct\"):\n",
    "    \"\"\"\n",
    "    Генерирует ответ от AI модели на основе системного промта и пользовательского сообщения.\n",
    "\n",
    "    Аргументы:\n",
    "    system_prompt (str): Системный промт для управления поведением AI.\n",
    "    user_message (str): Сообщение пользователя или запрос.\n",
    "    model (str): Модель для генерации ответа. По умолчанию \"meta-llama/Llama-2-7B-chat-hf\".\n",
    "\n",
    "    Возвращает:\n",
    "    dict: Ответ от AI модели.\n",
    "    \"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ]\n",
    "    )\n",
    "    return response\n",
    "\n",
    "# Создаём пользовательский промт на основе топовых чанков\n",
    "user_prompt = \"\\n\".join([f\"Context {i + 1}:\\n{chunk}\\n=====================================\\n\" for i, chunk in enumerate(top_chunks)])\n",
    "user_prompt = f\"{user_prompt}\\nQuestion: {query}\"\n",
    "\n",
    "# Генерируем AI ответ\n",
    "ai_response = generate_response(system_prompt, user_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка ответа AI\n",
    "Сравниваем ответ AI с ожидаемым ответом и присваиваем оценку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the evaluation criteria, I would assign a score of 0.5 to the AI assistant's response.\n",
      "\n",
      "The response is partially aligned with the true response, as it correctly identifies the main goal of Explainable AI (XAI) as making AI systems more transparent and understandable. However, it lacks some key details and nuances present in the true response. For example, the true response mentions the importance of assessing fairness and accuracy, which is not explicitly mentioned in the AI assistant's response. Additionally, the true response uses more precise language, such as \"providing insights into how they make decisions,\" which is not present in the AI assistant's response.\n"
     ]
    }
   ],
   "source": [
    "# Define the system prompt for the evaluation system\n",
    "evaluate_system_prompt = \"You are an intelligent evaluation system tasked with assessing the AI assistant's responses. If the AI assistant's response is very close to the true response, assign a score of 1. If the response is incorrect or unsatisfactory in relation to the true response, assign a score of 0. If the response is partially aligned with the true response, assign a score of 0.5.\"\n",
    "\n",
    "# Create the evaluation prompt by combining the user query, AI response, true response, and evaluation system prompt\n",
    "evaluation_prompt = f\"User Query: {query}\\nAI Response:\\n{ai_response.choices[0].message.content}\\nTrue Response: {data[0]['ideal_answer']}\\n{evaluate_system_prompt}\"\n",
    "\n",
    "# Generate the evaluation response using the evaluation system prompt and evaluation prompt\n",
    "evaluation_response = generate_response(evaluate_system_prompt, evaluation_prompt)\n",
    "\n",
    "# Print the evaluation response\n",
    "print(evaluation_response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}